{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de los dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La generación del conjunto de datos para el entrenamiento es una tarea compleja. En este caso, se ha abordado de la siguiente manera:\n",
    "1.\tSelección de Acuerdos a Nivel de Servicios. \n",
    "2.\tEmplear la biblioteca spacy para dividir el texto en oraciones.\n",
    "3.\tGenerar un csv con las sentencias y las categorías definidas.\n",
    "4.  Tras la clasificación algunas de las sentencias se han dividido o unificado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con la instalación e importación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos todos los textos a String para realizar una tokenización por oración con spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_string(list):\n",
    "    str = \"\"\n",
    "    for l in list:\n",
    "        str = str.replace(\"\\n\", \" \") + l\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement1 = convert_list_to_string(open(\"slas/aws_ec2_sla_may_2022.txt\", encoding=\"utf8\").readlines())\n",
    "agreement2 = convert_list_to_string(open(\"slas/google_engine_sla.txt\", encoding=\"utf8\").readlines())\n",
    "agreement3 = convert_list_to_string(open(\"slas/oracle_cloud_infrastructure_database_december_2022.txt\", encoding=\"utf8\").readlines())\n",
    "agreement4 = convert_list_to_string(open(\"slas/google_engine_sla.txt\", encoding=\"utf8\").readlines())\n",
    "agreement5 = convert_list_to_string(open(\"slas/microsoft_azure_kubernetes_sla_march_2020.txt\", encoding=\"utf8\").readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando con Spacy...\n",
      "Hecho.\n"
     ]
    }
   ],
   "source": [
    "print(\"Procesando con Spacy...\")\n",
    "textos_train = [agreement1, agreement2, agreement3, agreement4]\n",
    "textos_test = [agreement5]\n",
    "docs_train = list(nlp.pipe(textos_train))\n",
    "docs_test = list(nlp.pipe(textos_test))\n",
    "print(\"Hecho.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un listado de sentencias a clasificar para el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_train = []\n",
    "\n",
    "for i in range(len(docs_train)):\n",
    "  for sent in list(docs_train[i].sents):\n",
    "      sentence = str(sent)\n",
    "      sents_train.append(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un listado de sentencias a clasificar para la validación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_test = []\n",
    "for sent in list(docs_test[0].sents):\n",
    "    sentence = str(sent)\n",
    "    sents_test.append(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generación de los datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  service  metric  \\\n",
      "0                         Last Updated: May 25, 2022        0       0   \n",
      "1  This Amazon Compute Service Level Agreement (t...        0       0   \n",
      "2  In the event of a conflict between the terms o...        0       0   \n",
      "3  Capitalized terms used herein but not defined ...        0       0   \n",
      "4  *For purposes of this SLA, Amazon EC2 includes...        0       0   \n",
      "\n",
      "   objetive  remedies  claim  exception  definition  \n",
      "0         0         0      0          0           0  \n",
      "1         0         0      0          0           0  \n",
      "2         0         0      0          0           0  \n",
      "3         0         0      0          0           0  \n",
      "4         0         0      0          0           0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(sents_train, columns=[\"text\", ])\n",
    "df[\"service\"] = 0\n",
    "df[\"metric\"] = 0\n",
    "df[\"objetive\"] = 0\n",
    "df[\"remedies\"] = 0\n",
    "df[\"claim\"] = 0\n",
    "df[\"exception\"] = 0\n",
    "df[\"definition\"] = 0\n",
    "df.fillna(0, inplace=True)\n",
    "df.to_csv(\"slas/train_empty.csv\", index=False, encoding='utf-8')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  service  metric  \\\n",
      "0  SLA for Azure Kubernetes Service (AKS) Last up...        0       0   \n",
      "1  For customers who have purchased an Azure Kube...        0       0   \n",
      "2  The availability of the agent nodes in your AK...        0       0   \n",
      "3  Please see the Virtual Machines SLA for more d...        0       0   \n",
      "4  Introduction  This Service Level Agreement for...        0       0   \n",
      "\n",
      "   objetive  remedies  claim  exception  definition  \n",
      "0         0         0      0          0           0  \n",
      "1         0         0      0          0           0  \n",
      "2         0         0      0          0           0  \n",
      "3         0         0      0          0           0  \n",
      "4         0         0      0          0           0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(sents_test, columns=[\"text\", ])\n",
    "df[\"service\"] = 0\n",
    "df[\"metric\"] = 0\n",
    "df[\"objetive\"] = 0\n",
    "df[\"remedies\"] = 0\n",
    "df[\"claim\"] = 0\n",
    "df[\"exception\"] = 0\n",
    "df[\"definition\"] = 0\n",
    "df.fillna(0, inplace=True)\n",
    "df.to_csv(\"slas/validation_empty.csv\", index=False, encoding='utf-8')\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc2a200e1e6dab10c4dc3986f0e7a998296447c993c26561a1bd050a849d8214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
